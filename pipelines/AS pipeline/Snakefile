
# Where to generate the data
pathData = "/beegfs/XXXXXX/Projet-" + config["projet"] + "/"

conda_envs = "/beegfs/home/XXXXXX/envs/"
TMPDIR= "/beegfs/data/XXXXXX/tmp"

# Where sra are stored
pathSRA = "/beegfs/data/XXXXXX/ncbi/sra/"

# Where to localize the .bashrc
pathHome = "/beegfs/home/XXXXXX/"

pathLogiciels = pathHome + "Logiciels/"

# Where to find the pipeline
pathScriptsPl = pathHome + "Scripts/Projet-SplicedVariants/SVR_estimation/"

# Where to find run_BUSCO.py
pathPyBusco = pathHome + "Logiciels/busco/scripts/run_BUSCO.py"
busco_dir_out = "/beegfs/data/XXXXXX/ncbi/busco_run/"

# The BUSCO dataset choose (had to be previously downloaded as Busco/" + BUSCO_dataset_species + "_odb9/ )
BUSCO_dataset_species = config["BUSCO_dataset_species"]

# Where is the main excel file
Excel_dataset = pathData + "Fichiers-data/" + BUSCO_dataset_species + "_species.xls"

# Rules running in local not on the cluster
localrules: busco_blast_detection, download_NCBI_protein, download_NCBI_cds, download_NCBI_genome,
    download_NCBI_annotation, make_exon_blocks, intron_Coords, SRA_run_info, extract_intron_blocks

import numpy
import pandas as pd
import os, zipfile

# RNA-seq of each species
def collect_RNA(species):
    RNA = pd.read_table(pathData + "RNAseq_table/" + species + "/list_Acc.tab")
    return [Acc for Acc in RNA.SRA_accession_ID]

configfile: pathScriptsPl + config["dir_version"] + "/config"

all_species_to_study = config["all_species_to_study"]

all_SRA_Acc = dict(zip(all_species_to_study, [collect_RNA(species) for species in all_species_to_study]))


if config["ncbi_data"] == 'Yes':
    rule all:
        input:
            expand( pathData + "Annotations/{species}/data_source/cds_from_genomic.fna", species=all_species_to_study),
            expand( pathData + "Genomes/{species}/genome.fna", species=all_species_to_study),
            expand( pathData + "Annotations/{species}/data_source/protein.faa", species=all_species_to_study),
            expand( pathData + "Annotations/{species}/data_source/annotation.gtf", species=all_species_to_study)
else:
    rule all:
        input:
            expand( pathData + "Annotations/{species}/SRAruninfo.tab" , species=all_species_to_study),
            expand( pathData + "Analyses/{species}/by_intron_cds.tab" , species=all_species_to_study),
            expand( pathData + "Analyses/{species}/by_intron_major_overlap.tab" , species=all_species_to_study),
            expand( pathData + "Analyses/{species}/sequencing_depth.tab" , species=all_species_to_study),
            expand( pathData + "Analyses/{species}/by_gene_analysis.tab" , species=all_species_to_study),
            expand( pathData + "Analyses/{species}/by_minor_intron.tab" , species=all_species_to_study),
            expand( pathData + "Analyses/{species}/summary_characteristics.tab" , species=all_species_to_study),
            expand( pathData + "Annotations/{species}/busco_analysis/busco_to_gene_id_" + BUSCO_dataset_species , species=all_species_to_study),
            expand( pathData + "Analyses/{species}/by_gene_db.tab.gz" , species=all_species_to_study)




rule SRA_run_info:
    # Get information per RNA-seq
    params:
        time="01:00:00", mem=10000, partition="normal", ntasks=1, name="run_info_{species}",
        list_Acc_path = pathData + "RNAseq_table/{species}/list_Acc.tab"
    output:
        runinfo_path = pathData + "Annotations/{species}/SRAruninfo.tab"
    shell:
        """
        {pathLogiciels}/edirect/esearch -db sra -query "{wildcards.species}[Organism] AND TRANSCRIPTOMIC[Source]" | {pathLogiciels}/edirect/efetch -format runinfo > {output.runinfo_path}.csv
        Rscript --vanilla {pathScriptsPl}SRAruninfo_filtering.R {output.runinfo_path}.csv {output.runinfo_path} {params.list_Acc_path}
        rm {output.runinfo_path}.csv
        """

# Ne se lance que sur un noeud (-j = 1) sinon bug
rule download_NCBI_protein:
    # Telecharge le fichier de sequence proteique du NCBI
    output:
        prot_path = pathData + "Annotations/{species}/data_source/protein.faa"
    shell:
        "{pathScriptsPl}download_protein.sh {wildcards.species} {pathData} {pathHome} {output.prot_path}"

# Ne se lance que sur un noeud (-j = 1) sinon bug
rule download_NCBI_cds:
    # Telecharge le fichier de sequence CDS du NCBI
    output:
        cds_path = pathData + "Annotations/{species}/data_source/cds_from_genomic.fna"
    shell:
        "{pathScriptsPl}download_cds.sh {wildcards.species} {pathData} {pathHome} {output.cds_path}"

# Ne se lance que sur un noeud (-j = 1) sinon bug
rule download_NCBI_genome:
    # Telecharge le genome du NCBI
    output:
        genome_path = pathData + "Genomes/{species}/genome.fna"
    shell:
        "{pathScriptsPl}download_genome.sh {wildcards.species} {pathData} {pathHome} {output.genome_path}"

# Ne se lance que sur un noeud (-j = 1) sinon bug
rule download_NCBI_annotation:
    # Telecharge les annotations du NCBI
    output:
        gff_path = pathData + "Annotations/{species}/data_source/annotation.gff",
        gtf_path = pathData + "Annotations/{species}/data_source/annotation.gtf"
    shell:
        "{pathScriptsPl}download_annotation.sh {wildcards.species} {pathData} {pathHome} {output.gff_path} {output.gtf_path}"

rule genome_GC_content:
    # Calcule le nombre de C, A ,G et T dans le genome
    params: time="01:00:00", partition="normal", mem=20000, ntasks=1, name="GC_genome_{species}",
        out=pathData + "Output/Annotations_treatment/GC_content_{species}_out",
        err=pathData + "Output/Annotations_treatment/GC_content_{species}_err"
    input:
        genome_path = pathData + "Genomes/{species}/genome.fna"
    output:
        gc_table_path = pathData + "Annotations/{species}/GC_content.tab"
    shell:
        """
        echo "genome_character  Freq" > {output.gc_table_path}

        output_test=$(grep -o 'C\|c' {input.genome_path} | wc -l)
        echo "C $output_test" >> {output.gc_table_path}

        output_test=$(grep -o 'A\|a' {input.genome_path} | wc -l)
        echo "A $output_test" >> {output.gc_table_path}

        output_test=$(grep -o 'G\|g' {input.genome_path} | wc -l)
        echo "G $output_test" >> {output.gc_table_path}

        output_test=$(grep -o 'T\|t' {input.genome_path} | wc -l)
        echo "T $output_test" >> {output.gc_table_path}
        """

rule busco_blast_detection:
    # Realise un blast sur les sequence proteique des gène BUSCO afin d'attribuer une protéine à un gene BUSCO
    params:
        busco_db_path = pathData + "Busco/{BUSCO_dataset}_odb9/",
        busco_dir = pathData + "Annotations/{species}/busco_analysis/"
    input:
        protein_path = pathData + "Annotations/{species}/data_source/protein.faa"
    output:
        busco_csv_path = pathData + "Annotations/{species}/busco_analysis/busco_{BUSCO_dataset}.csv"
    shell:
        """
        mkdir -p {params.busco_dir}
        python {pathPyBusco} -i {input.protein_path} -o busco_{wildcards.species}_{wildcards.BUSCO_dataset} -l {params.busco_db_path} -m proteins -f
        cp {busco_dir_out}run_busco_{wildcards.species}_{wildcards.BUSCO_dataset}/full_table_busco_{wildcards.species}_{wildcards.BUSCO_dataset}.tsv {pathData}Annotations/{wildcards.species}/full_table_busco_{wildcards.species}_{wildcards.BUSCO_dataset}.tsv
        rm -r {busco_dir_out}run_busco_{wildcards.species}_{wildcards.BUSCO_dataset}
        tr '\t' ',' < {pathData}Annotations/{wildcards.species}/full_table_busco_{wildcards.species}_{wildcards.BUSCO_dataset}.tsv > {output.busco_csv_path}
        rm {pathData}Annotations/{wildcards.species}/full_table_busco_{wildcards.species}_{wildcards.BUSCO_dataset}.tsv
        """

rule busco_to_gene_id:
    # A partir du fichier d'annotation associer la proteine BUSCO à son gène
    params: time="00:20:00", mem=1000,partition="normal", ntasks=1, name="busco_gene_{species}_{BUSCO_dataset}",
        out=pathData + "Output/Annotations_treatment/busco_to_gene_id_{BUSCO_dataset}_{species}_out",
        err=pathData + "Output/Annotations_treatment/busco_to_gene_id_{BUSCO_dataset}_{species}_err"
    input:
        busco_csv_path=pathData + "Annotations/{species}/busco_analysis/busco_{BUSCO_dataset}.csv",
        gff_path=pathData + "Annotations/{species}/data_source/annotation.gff",
        cds_from_genomic_path = pathData + "Annotations/{species}/data_source/cds_from_genomic.fna"
    output:
        busco_to_gene_path = pathData + "Annotations/{species}/busco_analysis/busco_to_gene_id_{BUSCO_dataset}"
    shell:
        """
        python -u {pathScriptsPl}busco_to_gene_id.py {input.gff_path} {input.busco_csv_path} {input.cds_from_genomic_path} {output.busco_to_gene_path}
        """


rule build_genome_index:
    # Construit l Index HISAT pour l alignement sur le genome
    params:
        index=pathData + "Genomes/{species}/Index",
        time="120:00:00", mem=20000,partition="normal", ntasks=32, name="genome_index_{species}",
        out=pathData + "Output/Hisat/Indexer/indexer_{species}_out",
        err=pathData + "Output/Hisat/Indexer/indexer_{species}_err"
    input:
        gtf_path = pathData + "Annotations/{species}/data_source/annotation.gtf",
        genome_path = pathData + "Genomes/{species}/genome.fna"
    output:
        pathData + "Genomes/{species}/Index.1.ht2",
        Exon = pathData + "Annotations/{species}/formatted_data/Exons.tab",
        SpliceSites = pathData + "Annotations/{species}/formatted_data/SpliceSites.tab"
    shell:
        """
        source {pathHome}.bashrc
        conda activate hisatfastq
        which hisat2
        find {pathData}/Genomes/{wildcards.species} -type f -name "Index*" -delete
        {pathLogiciels}hisat2-2.2.1/extract_splice_sites.py {input.gtf_path} > {output.SpliceSites}
        {pathLogiciels}hisat2-2.2.1/extract_exons.py {input.gtf_path} > {output.Exon}
        which hisat2-build
        hisat2-build -p {params.ntasks} --ss {output.SpliceSites} --exon {output.Exon} --seed 19 {input.genome_path} {params.index}
        """

rule alignment_hisat:
    # Alignement sur le genome
    params:
        time="120:00:00", mem=10000, partition="normal", ntasks=16, name="alignment_hisat_{species}_{rna}",
        directory=pathData + "Alignements/{species}/{rna}/",
        index=pathData + "Genomes/{species}/Index",
        out=pathData + "Output/Hisat/Alignement/alignment_{species}_{rna}_out",
        err=pathData + "Output/Hisat/Alignement/alignment_{species}_{rna}_err"
    input:
        pathData + "Genomes/{species}/Index.1.ht2",
        SpliceSites = pathData + "Annotations/{species}/formatted_data/SpliceSites.tab"
    output:
        alignement_bam = pathData + "Alignements/{species}/{rna}/accepted_hits.bam"
    shell:
        """
        cd {pathSRA}
        source {pathHome}.bashrc
        conda activate hisatfastq
        mkdir -p {params.directory}
        
        parallel-fastq-dump --tmpdir {pathSRA} --sra-id {wildcards.rna} --threads {params.ntasks} --outdir {pathSRA} --split-files --split-3

        ls {pathSRA}{wildcards.rna}* -l
        wc -l {pathSRA}{wildcards.rna}*

        if [ -f {pathSRA}{wildcards.rna}_1.fastq ] && [ -f {pathSRA}{wildcards.rna}_2.fastq ];then
            echo "Paired !"
            {pathLogiciels}hisat2-2.1.0/hisat2 --seed 19 -p {params.ntasks} -x {params.index} -S {params.directory}accepted_hits.sam --known-splicesite-infile={input.SpliceSites} --max-intronlen 2000000 --dta-cufflinks --no-unal --met-file {params.directory}metrics.txt --novel-splicesite-outfile {params.directory}novel_splicesites.txt -q -1 {pathSRA}{wildcards.rna}_1.fastq  -2 {pathSRA}{wildcards.rna}_2.fastq
        elif [ -f {pathSRA}{wildcards.rna}.fastq ] && [ ! -f {pathSRA}{wildcards.rna}_2.fastq ] && [ ! -f {pathSRA}{wildcards.rna}_1.fastq ];then
            echo "Single !"
            {pathLogiciels}hisat2-2.1.0/hisat2 --seed 19 -p {params.ntasks} -x {params.index} -S {params.directory}accepted_hits.sam --known-splicesite-infile={input.SpliceSites} --max-intronlen 2000000 --dta-cufflinks --no-unal --met-file {params.directory}metrics.txt --novel-splicesite-outfile {params.directory}novel_splicesites.txt -q -U {pathSRA}{wildcards.rna}.fastq
        elif [ -f {pathSRA}{wildcards.rna}_3.fastq ];then
            echo "Test Failed !"
        fi
        perl {pathScriptsPl}cleanup.sam.pl --pathInput={params.directory}accepted_hits.sam --pathOutput={params.directory}accepted_hits_clean.sam
        /beegfs/XXXXXX/soft/singularity-3.7.2/bin/singularity exec --bind /beegfs/data/XXXXXX:/beegfs/data/XXXXXX /beegfs/home/XXXXXX/dockers/samtools.simg samtools sort -@ 6 -o {output.alignement_bam} -O bam {params.directory}accepted_hits_clean.sam
        rm {params.directory}accepted_hits_clean.sam {params.directory}accepted_hits.sam {params.directory}metrics.txt
        rm -f -r {pathSRA}{wildcards.rna}*
        rm -f {pathSRA}{wildcards.rna}*
        """


rule compute_genome_coverage:
    # Calcule le nombre de reads mappé par pb du genome
    params:
        time="01:00:00", mem=10000,partition="normal", ntasks=1, name="genome_coverage_{species}_{rna}",
        DIRbedGraph=pathData + "Alignements/{species}/{rna}/read_coverage.bedGraph",
        out=pathData + "Output/Sequencing_depth/compute_genome_coverage_{species}_{rna}_out",
        err=pathData + "Output/Sequencing_depth/compute_genome_coverage_{species}_{rna}_err"
    input:
        alignement_bam=pathData + "Alignements/{species}/{rna}/accepted_hits.bam"
    output:
        pathData + "Alignements/{species}/{rna}/read_coverage.bedGraph.gz"
    shell:
        """
        {pathLogiciels}watchlin/watchlin -f {pathData}Output/Watchlin/coverage_alignment_{wildcards.species}_{wildcards.rna}_log -c "bedtools genomecov -bg -split -ibam {input.alignement_bam} > {params.DIRbedGraph}"
        gzip -f {params.DIRbedGraph}
        """

rule make_exon_blocks:
    # Recherche les blocs exoniques dans le fichier d'annotation, cad les bloc uniquement présent dans les exons
    input:
        annotation=pathData + "Annotations/{species}/data_source/annotation.gtf"
    output:
        annotation_gene_id = pathData + "Annotations/{species}/formatted_data/annotation_gene_id.gtf",
        exon_union = pathData + "Annotations/{species}/formatted_data/exon_union.tab"
    shell:
        """
        grep gene_id {input.annotation} > {output.annotation_gene_id}
        perl {pathScriptsPl}make.exon.blocks.gtf.pl --pathGTF={output.annotation_gene_id} --collapseDistance=0  --pathOutputExonBlocks={output.exon_union}
        """

rule extract_intron_blocks:
    # Extrait les blocs introniques, l'intersection des blocs exoniques
    input:
        exon_union=pathData + "Annotations/{species}/formatted_data/exon_union.tab"
    output:
        intronIntersection=pathData + "Annotations/{species}/formatted_data/intron_intersection.tab"
    shell:
        """
        perl {pathScriptsPl}extract.intron.blocks.pl --pathExonBlocks={input.exon_union} --pathOutputIntronBlocks={output.intronIntersection}
        """

rule compute_gene_coverage:
    # Recherche la couverture par gène sur les exons et les introns.
    params: time = "10:00:00", mem=10000, partition="normal", ntasks=1, name="gene_coverage_{species}_{rna}",
        out = pathData + "Output/Sequencing_depth/compute_gene_coverage_{species}_{rna}_out",
        err = pathData + "Output/Sequencing_depth/compute_gene_coverage_{species}_{rna}_err"
    input:
        exon_union = pathData + "Annotations/{species}/formatted_data/exon_union.tab",
        intronIntersection = pathData + "Annotations/{species}/formatted_data/intron_intersection.tab",
        bedgraph_path = pathData + "Alignements/{species}/{rna}/read_coverage.bedGraph.gz"
    output:
        exonCoverage = pathData + "Analyses-RNAseq/{species}/{rna}/coverage_genes_exons.txt",
        intronCoverage = pathData + "Analyses-RNAseq/{species}/{rna}/coverage_genes_introns.txt"
    shell:
        """
        perl  {pathScriptsPl}compute.gene.coverage.pl --pathExonBlocks={input.exon_union} --pathCoverage={input.bedgraph_path} --pathOutputGenes={output.exonCoverage} --pathOutputExons={pathData}Analyses-RNAseq/{wildcards.species}/{wildcards.rna}/coverage_exons.txt
        perl  {pathScriptsPl}compute.gene.coverage.pl --pathExonBlocks={input.intronIntersection} --pathCoverage={input.bedgraph_path} --pathOutputGenes={output.intronCoverage} --pathOutputExons={pathData}Analyses-RNAseq/{wildcards.species}/{wildcards.rna}/coverage_introns.txt
        rm {pathData}Analyses-RNAseq/{wildcards.species}/{wildcards.rna}/coverage_introns.txt {pathData}Analyses-RNAseq/{wildcards.species}/{wildcards.rna}/coverage_exons.txt
        """

rule extract_junctions_hisat:
    # Extrait les jonctions de l'alignement .bam
    params: time="04:00:00", mem=15000, partition="normal",ntasks=1, name="junctions_hisat_{species}_{rna}",
        out=pathData + "Output/Splicing_analysis/extract_junctions_hisat_{species}_{rna}_out",
        err=pathData + "Output/Splicing_analysis/extract_junctions_hisat_{species}_{rna}_err"
    input:
        genome=pathData + "Genomes/{species}/genome.fna",
        alignement=pathData + "Alignements/{species}/{rna}/accepted_hits.bam"
    output:
        junction=pathData + "Analyses-RNAseq/{species}/{rna}/junctions.txt",
        junctionWrongstrand=pathData + "Analyses-RNAseq/{species}/{rna}/junctions_wrongstrand.txt"
    shell:
        """
        mkdir -p {pathData}Analyses-RNAseq/{wildcards.species}/{wildcards.rna}
        perl {pathScriptsPl}extract.junctions.hisat.pl --pathAln={input.alignement} --pathGenomeSequence={input.genome} --anchordetection=8 --anchorquantification=5 --maxmismatch=0.02 --pathOutput={output.junction} --pathOutputWrongStrand={output.junctionWrongstrand}
        """

rule intron_Coords:
    # Extrait les coordonnées des introns à partir du .gtf et leur site d'epissage
    input:
        gtf_path = pathData + "Annotations/{species}/data_source/annotation.gtf",
        genome_path = pathData + "Genomes/{species}/genome.fna"
    output:
        introncoord_path = pathData + "Annotations/{species}/formatted_data/IntronCoords.tab"
    shell:
        """
        perl {pathScriptsPl}extract.introns.annotations.pl --pathGTF={input.gtf_path} --pathGenomeSequence={input.genome_path} --pathOutput={output.introncoord_path}
        """

rule assign_junctions_genes_inclusive:
    # Assigne les jonctions aux gènes, cad un intron est dans un gène s'il a au moins une borne dans un intron ?!
    params: time="05:00:00", mem=7000, partition="normal", ntasks=1, name="assign_jnct_{species}_{rna}",
        out=pathData + "Output/Splicing_analysis/genes_to_jnct_{species}_{rna}_out",
        err=pathData + "Output/Splicing_analysis/genes_to_jnct_{species}_{rna}_err"
    input:
        annotation=pathData + "Annotations/{species}/data_source/annotation.gtf",
        junction=pathData + "Analyses-RNAseq/{species}/{rna}/junctions.txt"
    output:
        junction_gene_ids=pathData + "Analyses-RNAseq/{species}/{rna}/junctions_gene_ids_inclusive.txt"
    shell:
        """
        perl {pathScriptsPl}assign.junctions.genes.inclusive.pl --margin=0 --pathGTF={input.annotation} --pathSpliceJunctions={input.junction} --pathOutput={output.junction_gene_ids}
        """

def junction_ids_inclusive(wildcards):
    return expand(pathData + "Analyses-RNAseq/" + wildcards.species + "/{rnasp}/junctions_gene_ids_inclusive.txt",rnasp = all_SRA_Acc[wildcards.species])

rule compute_intron_library:
    # Combine tous les introns découvert dans les alignements + ceux qui sont dans le fichier d'annotation dans une library
    params: time="24:00:00", mem=10000, partition="normal", ntasks=1, name="intron_library_{species}",
        out=pathData + "Output/Splicing_analysis/compute_intron_library_{species}_out",
        err=pathData + "Output/Splicing_analysis/compute_intron_library_{species}_err",
        list_rna = pathData + "RNAseq_table/{species}/list_Acc.tab"
    input:
        junction_gene_ids = junction_ids_inclusive,
        genome=pathData + "Genomes/{species}/genome.fna",
        IntronCoords = pathData + "Annotations/{species}/formatted_data/IntronCoords.tab"
    output:
        IntronLibrary=pathData + "Analyses/{species}/IntronLibrary_inclusive.txt"
    shell:
        """
        mkdir -p {pathData}Analyses/{wildcards.species}
        Rscript --vanilla {pathScriptsPl}combine.introns.R {wildcards.species} {pathData} {input.IntronCoords} {input.genome} {output.IntronLibrary} {params.list_rna}
        """

rule compute_SVR:
    # Pour chaque alignements comptage des N2 en partant de la library d'introns
    params: time="01:00:00", mem=10000, partition="normal",ntasks=1, name="SVR_{species}_{rna}",
        out=pathData + "Output/Splicing_analysis/compute_SVR_{species}_{rna}_out",
        err=pathData + "Output/Splicing_analysis/compute_SVR_{species}_{rna}_err"
    input:
        IntronLibrary=pathData + "Analyses/{species}/IntronLibrary_inclusive.txt",
        junction_gene_ids=pathData + "Analyses-RNAseq/{species}/{rna}/junctions_gene_ids_inclusive.txt"
    output:
        SVR_Frequency=pathData + "Analyses-RNAseq/{species}/{rna}/SVR_Frequency_inclusive.txt"
    shell:
        """
        perl {pathScriptsPl}compute.alternative.splicing.frequency.pl --pathIntronLibrary={input.IntronLibrary} --pathSpliceJunctions={input.junction_gene_ids} --pathOutput={output.SVR_Frequency}
        """

rule compute_NSVR:
    # Pour chaque alignements comptage des N3 en partant de la library d'introns
    params: time="10:00:00", mem=10000, partition="normal",ntasks=1, name="NSVR_{species}_{rna}",
        out=pathData + "Output/Retention_analysis/compute_NSVR_{species}_{rna}_out",
        err=pathData + "Output/Retention_analysis/compute_NSVR_{species}_{rna}_err"
    input:
        IntronLibrary=pathData + "Analyses/{species}/IntronLibrary_inclusive.txt",
        alignement=pathData + "Alignements/{species}/{rna}/accepted_hits.bam"
    output:
        NSVR_Frequency=pathData + "Analyses-RNAseq/{species}/{rna}/NSVR_Frequency_inclusive.txt"
    shell:
        """
        perl {pathScriptsPl}junction.spanning.reads.pl --pathIntronLibrary={input.IntronLibrary} --pathAlignment={input.alignement} --sizeOverlap=10 --onlyUnique=1 --pathOutput={output.NSVR_Frequency}
        """

rule cufflinks:
    # Calcule des FPKM
    params: time="06-00:00:00", mem=20000, partition="normal",ntasks=16, name="cufflinks_{species}_{rna}",
        out=pathData + "Output/Expression/cufflinks_{species}_{rna}_out",
        err=pathData + "Output/Expression/cufflinks_{species}_{rna}_err",
        output_path = pathData + "Analyses-RNAseq/{species}/{rna}/"
    input:
        genome=pathData + "Genomes/{species}/genome.fna",
        annotation=pathData + "Annotations/{species}/data_source/annotation.gtf",
        alignement_bam=pathData + "Alignements/{species}/{rna}/accepted_hits.bam"
    output:
        pathData + "Analyses-RNAseq/{species}/{rna}/isoforms.fpkm_tracking.gz",
        pathData + "Analyses-RNAseq/{species}/{rna}/genes.fpkm_tracking.gz",
        pathData + "Analyses-RNAseq/{species}/{rna}/skipped.gtf.gz",
        pathData + "Analyses-RNAseq/{species}/{rna}/transcripts.gtf.gz"
    shell:
        """
        source {pathHome}.bashrc
        conda activate python36
        mkdir -p {pathData}Analyses/{wildcards.species}
        mkdir -p {pathData}Analyses-RNAseq/{wildcards.species}/{wildcards.rna}
        {pathLogiciels}watchlin/watchlin -f {pathData}Output/Watchlin/cufflinks_{wildcards.species}_{wildcards.rna}_log -c "cufflinks -p {params.ntasks} -o {params.output_path} --multi-read-correct --max-intron-length 2000000 --library-type fr-unstranded -b {input.genome} -G {input.annotation} {input.alignement_bam}"
        #rm {params.output_path}skipped.gtf {params.output_path}transcripts.gtf
        gzip {params.output_path}skipped.gtf
        gzip {params.output_path}transcripts.gtf
        gzip {params.output_path}isoforms.fpkm_tracking
        gzip {params.output_path}genes.fpkm_tracking
        """

rule by_gene_by_rnaseq:
    params: time="00:10:00", mem=5000, partition="normal", ntasks=1, name="gene_rnaseq_{species}_{rna}",
        out=pathData + "Output/Compilation/by_gene_by_rnaseq_{species}_{rna}_out",
        err=pathData + "Output/Compilation/by_gene_by_rnaseq_{species}_{rna}_err"
    input:
        gtf_path = pathData + "Annotations/{species}/data_source/annotation.gtf",
        gene_fpkm_path = pathData + "Analyses-RNAseq/{species}/{rna}/genes.fpkm_tracking.gz",
        gene_intron_coverage_path = pathData + "Analyses-RNAseq/{species}/{rna}/coverage_genes_introns.txt",
        gene_exon_coverage_path = pathData + "Analyses-RNAseq/{species}/{rna}/coverage_genes_exons.txt"
    output:
        gene_analysis_report_path = pathData + "Analyses-RNAseq/{species}/{rna}/coverage_fpkm_by_genes.tab"
    shell:
        """
        python3.9 -u {pathScriptsPl}cov_fpkm_per_gene.py {input.gtf_path} {input.gene_intron_coverage_path} {input.gene_exon_coverage_path} {input.gene_fpkm_path} {output.gene_analysis_report_path}
        """

rule intron_by_rnaseq:
    params: time="00:10:00", mem=5000, partition="normal", ntasks=1, name="intron_rnaseq_{species}_{rna}",
        out=pathData + "Output/Compilation/intron_by_rnaseq_{species}_{rna}_out",
        err=pathData + "Output/Compilation/intron_by_rnaseq_{species}_{rna}_err"
    input:
        nsvr_path= pathData + "Analyses-RNAseq/{species}/{rna}/NSVR_Frequency_inclusive.txt",
        svr_path= pathData + "Analyses-RNAseq/{species}/{rna}/SVR_Frequency_inclusive.txt"
    output:
        output_path = pathData + "Analyses-RNAseq/{species}/{rna}/n1_n2_n3_by_intron.tab"
    shell:
        """
        python3.9 -u {pathScriptsPl}n1_n2_n3_per_intron.py {input.nsvr_path} {input.svr_path} {output.output_path}
        """

def all_report_by_intron(wildcards):
    return expand(pathData + "Analyses-RNAseq/" + wildcards.species + "/{rnasp}/n1_n2_n3_by_intron.tab",rnasp=all_SRA_Acc[wildcards.species])

def all_report_by_gene(wildcards):
    return expand(pathData + "Analyses-RNAseq/" + wildcards.species + "/{rnasp}/coverage_fpkm_by_genes.tab",rnasp=all_SRA_Acc[wildcards.species])

rule pool_analysis:
    # Faire une table qui reprend tout par projet
    params: time="0:30:00", mem=5000, partition="normal",ntasks=1, name="pool_analysis_{species}",
        out=pathData + "Output/Compilation/pool_analysis_{species}_out",
        err=pathData + "Output/Compilation/pool_analysis_{species}_err",
        path_output = pathData + "Analyses/{species}/bioproject_analysis/",
        path_input = pathData + "Analyses-RNAseq/{species}/",
        list_Acc_path = pathData + "RNAseq_table/{species}/list_Acc.tab"
    input:
        all_report_by_gene,
        all_report_by_intron,
        gff_path = pathData +"Annotations/{species}/data_source/annotation.gff"
    output:
        by_intron_analysis_path = pathData + "Analyses/{species}/by_intron_analysis.tab",
        by_gene_analysis_path = pathData + "Analyses/{species}/by_gene_analysis.tab"
    shell:
        """
        rm -r -f {params.path_output}
        mkdir -p {params.path_output}
        python3.9 -u {pathScriptsPl}pool_analysis.py {params.path_output} {params.path_input} {params.list_Acc_path} {input.gff_path} {output.by_intron_analysis_path} {output.by_gene_analysis_path}
        """


rule pool_db:
    # Faire une table qui reprend tout par projet
    params: time="0:30:00", mem=5000, partition="normal",ntasks=1, name="pool_db_{species}",
        out=pathData + "Output/Compilation/pool_db_{species}_out",
        err=pathData + "Output/Compilation/pool_db_{species}_err",
        path_input = pathData + "Analyses-RNAseq/{species}/",
        list_Acc_path = pathData + "RNAseq_table/{species}/list_Acc.tab",
        by_gene_db_path = pathData + "Analyses/{species}/by_gene_db.tab",
        by_intron_db_path = pathData + "Analyses/{species}/by_intron_db.tab"
    input:
        all_report_by_gene,
        all_report_by_intron,
        gff_path = pathData +"Annotations/{species}/data_source/annotation.gff"
    output:
        by_intron_db_gz = pathData + "Analyses/{species}/by_intron_db.tab.gz",
        by_gene_db_gz = pathData + "Analyses/{species}/by_gene_db.tab.gz"
    shell:
        """
        python3.9 -u {pathScriptsPl}pool_db.py {params.path_input} {params.list_Acc_path} {input.gff_path} {params.by_intron_db_path} {params.by_gene_db_path}
        gzip {params.by_intron_db_path}
        gzip {params.by_gene_db_path}
        """

rule intron_cds_detector:
    # Faire une table qui reprend tout par projet
    params: time="01:30:00", mem=5000, partition="normal",ntasks=1, name="intron_cds_{species}",
        out=pathData + "Output/Compilation/intron_cds_detector_{species}_out",
        err=pathData + "Output/Compilation/intron_cds_detector_{species}_err",
        list_Acc_path = pathData + "RNAseq_table/{species}/list_Acc.tab"
    input:
        by_intron_analysis_path = pathData + "Analyses/{species}/by_intron_analysis.tab",
        gff_path = pathData +"Annotations/{species}/data_source/annotation.gff"
    output:
        by_intron_cds_path = pathData + "Analyses/{species}/by_intron_cds.tab",
        gene_coord_path = pathData + "Analyses/{species}/genes_coord.tab"
    shell:
        """
        python3.9 -u {pathScriptsPl}intron_cds_detector.py {input.gff_path} {input.by_intron_analysis_path} {params.list_Acc_path} {output.gene_coord_path} {output.by_intron_cds_path}
        """


rule minor_intron_detector:
    # Faire une table qui reprend tout par projet
    params: time="02:30:00", mem=10000, partition="normal",ntasks=1, name="minor_intron_{species}",
        out=pathData + "Output/Compilation/minor_intron_detector_{species}_out",
        err=pathData + "Output/Compilation/minor_intron_detector_{species}_err"
    input:
        by_intron_cds_path = pathData + "Analyses/{species}/by_intron_cds.tab"
    output:
        minor_intron_path = pathData + "Analyses/{species}/by_minor_intron.tab"
    shell:
        """
        python3.9 -u {pathScriptsPl}minor_intron_detector.py {input.by_intron_cds_path} {output.minor_intron_path}
        """

rule overlap_detection:
    # Faire une table qui reprend tout par projet
    params: time="05:30:00", mem=10000, partition="normal",ntasks=1, name="overlap_detection_{species}",
        out=pathData + "Output/Compilation/overlap_detection_{species}_out",
        err=pathData + "Output/Compilation/overlap_detection_{species}_err"
    input:
        by_intron_cds_path = pathData + "Analyses/{species}/by_intron_cds.tab",
        fpkm_cov_path = pathData + "Analyses/{species}/by_gene_analysis.tab",
        minor_introns_path = pathData + "Analyses/{species}/by_minor_intron.tab"
    output:
        overlap_path = pathData + "Analyses/{species}/by_intron_major_overlap.tab"
    shell:
        """
        python3.9 -u {pathScriptsPl}overlap_detection.py {input.by_intron_cds_path} {output.overlap_path} {input.fpkm_cov_path} {input.minor_introns_path}
        """


rule major_triplet:
    # Faire une table qui reprend tout par projet  
    params: time="7-00:30:00", mem=10000, partition="long",ntasks=1, name="major_triplet_{species}",
        out=pathData + "Output/Compilation/major_triplet_{species}_out",
        err=pathData + "Output/Compilation/major_triplet_{species}_err"
    input:
        genome_path = pathData + "Genomes/{species}/genome.fna",
        library_path = pathData + "Analyses/{species}/by_intron_major_overlap.tab"
    output:
        trinucl_intronic_path = pathData + "Analyses/{species}/by_intron_major_overlap_triplet.tab"
    shell:
        """
        python3.9 -u {pathScriptsPl}trinucl_intronic.py {input.genome_path} {input.library_path} {output.trinucl_intronic_path}
        """


rule summary_characteristics:
    # Calcule du taux de SVR en fonciton de la profondeur de sequencage
    params: time="00-15:00:00", mem=5000, partition="normal",ntasks=1, name="summary_v3_{species}",
        out=pathData + "Output/Compilation/summary_v3_{species}_out",
        err=pathData + "Output/Compilation/summary_v3_{species}_err"
    input:
        gff_path = pathData + "Annotations/{species}/data_source/annotation.gff",
        gc_table_path = pathData+ "Annotations/{species}/GC_content.tab",
        library_path = pathData +  "Analyses/{species}/IntronLibrary_inclusive.txt",
        by_intron_cds_path = pathData+ "Analyses/{species}/by_intron_cds.tab",
        by_gene_analysis_path = pathData+ "Analyses/{species}/by_gene_analysis.tab",
        by_intron_overlap_path = pathData+ "Analyses/{species}/by_intron_major_overlap.tab",
        prot_path = pathData + "Annotations/{species}/data_source/protein.faa"
    output:
        sumv3_path = pathData + "Analyses/{species}/summary_characteristics.tab"
    shell:
        """
        Rscript --vanilla {pathScriptsPl}summary_script.R {pathData} {wildcards.species} {Excel_dataset} {input.gff_path} {input.gc_table_path} {input.library_path} {input.by_intron_cds_path} {input.by_gene_analysis_path} {input.by_intron_overlap_path} {input.prot_path} {output.sumv3_path}
        """


rule variance_table_version:
    # Calcule du taux de SVR en fonciton de la profondeur de sequencage
    params: time="24:00:00", mem=1000, partition="normal",ntasks=1, name="var4_table_{species}",
        out=pathData + "Output/Compilation/var4_table_{species}_out",
        err=pathData + "Output/Compilation/var4_table_{species}_err",
        RNAseq_table=pathData + "RNAseq_table/{species}/list_Acc.tab"
    input:
        all_report_by_gene,
        all_report_by_intron,
        by_intron_cds_path=pathData + "Analyses/{species}/by_intron_cds.tab",
        IntronCoord_path=pathData +  "Annotations/{species}/formatted_data/IntronCoords.tab",
        busco_path = pathData + "Annotations/{species}/busco_analysis/busco_to_gene_id_" + BUSCO_dataset_species
    output:
        varianceTable = pathData + "Analyses/{species}/sequencing_depth.tab"
    shell:
        """
        Rscript --vanilla {pathScriptsPl}seq_depth_charac.R {wildcards.species} {pathData} {input.by_intron_cds_path} {input.IntronCoord_path} {input.busco_path} {output.varianceTable} {params.RNAseq_table}
        """


